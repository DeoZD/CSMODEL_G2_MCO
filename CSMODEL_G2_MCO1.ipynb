{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DeoZD/CSMODEL_G2_MCO/blob/main/CSMODEL_G2_MCO1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **CSMODEL MCO1 Group 2**\n",
        "## LaSalleGameKNB?\n",
        "* TIONGCO, KYAN THOMAS    S18\n",
        "* DIAMANTE, DEO ZAMIR     S19\n",
        "* LICUP, EVAN GABRIEL     S19\n",
        "* SARROZA, MIKAEL JENSON\tS19"
      ],
      "metadata": {
        "id": "vVTjMOTRhdqV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GamingStudy_data.csv\n",
        "The original dataset consists of data collected as a part of a survey among gamers worldwide. The questionnaire asked questions that psychologists generally ask people who are prone to anxiety, social phobia, and less to no life satisfaction. The questionnaire consists of several set of questions as asked as a part of psychological study. The original data was collated by Marian Sauter and Dejan Draschkow."
      ],
      "metadata": {
        "id": "Yha6koLR_yBZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import missingno as msno\n",
        "import seaborn as sns\n",
        "import re\n",
        "\n",
        "# sets the theme of the charts\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "url = 'https://github.com/DeoZD/CSMODEL_G2_MCO/raw/refs/heads/main/GamingStudy_data.csv'\n",
        "orig_df = pd.read_csv(url, encoding='latin-1')"
      ],
      "metadata": {
        "id": "eGD72MbiiqJ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Original dataframe information:"
      ],
      "metadata": {
        "id": "6a0rcyCQqwWH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "orig_df.info()"
      ],
      "metadata": {
        "id": "keRTmEnSJwFF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Cleaning"
      ],
      "metadata": {
        "id": "n_OkF0Fey8oV"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2a73b2dd"
      },
      "source": [
        "# @title Remove `highestleague` as it's empty\n",
        "pre_df = orig_df.drop(columns=['highestleague'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Remove `accept` as it's not indicative of what the survey data entails\n",
        "pre_df = pre_df.drop(columns=['accept'])"
      ],
      "metadata": {
        "id": "wHEcEB_MFoW3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note**: `accept` is meant to be the variable for Consent in survey participation, having either `Accept` or `NA` as values.\n",
        "\n",
        "The value of `NA` means that the Consent step was skipped, as unlike the main study questions which were marked as required, the Consent part of the used survey form was not marked as such.\n",
        "\n",
        "The used survey form states that not answering or not finishing the survey is the only way the data is not stored or shared.\n",
        "\n",
        "Given that even if `accept` is `NA`, there are still participants *who answered the required parts of the survey until they finished*, we choose to interpret this as **\"Consent by Action.\"**\n",
        "\n",
        "By continuing to the next pages and answering the demographic and/or study-specific questions, the participant effectively demonstrated their willingness to participate.\n",
        "\n",
        "The `NA` isn't treated as a \"No\"—just a skipped administrative step.\n",
        "\n",
        "![accept](https://raw.githubusercontent.com/DeoZD/CSMODEL_G2_MCO/39481709c624a3431f3db90e0c1b8f9e033b5e3b/assets%20/accept.png)"
      ],
      "metadata": {
        "id": "xj32-qRIPI8k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Remove other irrelevant variables (`Reference`, `Timestamp`, `S. No.`)\n",
        "pre_df = pre_df.drop(columns=['Reference', 'Timestamp', 'S. No.'])"
      ],
      "metadata": {
        "id": "671tZR_2epTo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Clean `League` categories\n",
        "\n",
        "# Get the unique values to assess which values should stay or be removed\n",
        "# pre_df['League'].unique()\n",
        "# pre_df['League'].nunique()\n",
        "# pre_df['League'].drop_duplicates().to_csv(\"unique_rank.csv\", index=False)"
      ],
      "metadata": {
        "id": "uhtuN35N7p7a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_rank(x):\n",
        "    rank_order = ['bronze', 'silver', 'gold', 'platinum', 'diamond', 'master', 'grandmaster', 'challenger']\n",
        "\n",
        "    if pd.isna(x) or not str(x).strip():\n",
        "        return np.nan\n",
        "\n",
        "    x = str(x).lower().strip()\n",
        "\n",
        "    # UNRANKED (PRIORITY)\n",
        "    unranked_patterns = [\n",
        "        r'\\b(unranked|not\\s+ranked|no\\s+rank|unraked|unrankt|unrank)\\b',\n",
        "        r'\\b(placement|provisional|seeding|qualifying|not\\s+placed|still\\s+placing)\\b',\n",
        "        r'\\b(not\\s+applicable|n/a|na|none)\\b',\n",
        "        r'\\b(dont\\s+play|don\\'t\\s+play|never\\s+played|havent\\s+played)\\s+ranked\\b',\n",
        "        r'\\b(havent|haven\\'t)\\s+(?:done|played)\\s+(?:ranked|placement)\\b',\n",
        "        r'\\b(under|pre|not)\\s*(?:level|30|lvl)\\b',\n",
        "        r'\\b(aram|normal|casual)\\s+only\\b',\n",
        "        r'\\b(too\\s+toxic|rank\\s+anxiety|anxiousness)\\b',\n",
        "        r'\\b0\\s*(?:games|ranked)\\b',\n",
        "    ]\n",
        "\n",
        "    for pattern in unranked_patterns:\n",
        "        if re.search(pattern, x):\n",
        "            return 'unranked'\n",
        "\n",
        "    found_ranks = set()\n",
        "\n",
        "    # FULL WORD RANKS\n",
        "    for rank in rank_order:\n",
        "        if re.search(rf'\\b{rank}\\b', x):\n",
        "            found_ranks.add(rank)\n",
        "\n",
        "    # LETTER-NUMBER RANKS\n",
        "    ln_map = {\n",
        "        'b': 'bronze',\n",
        "        's': 'silver',\n",
        "        'g': 'gold',\n",
        "        'p': 'platinum',\n",
        "        'd': 'diamond',\n",
        "        'm': 'master',\n",
        "        'gm': 'grandmaster',\n",
        "        'ch': 'challenger'\n",
        "    }\n",
        "\n",
        "    ln_matches = re.findall(r'\\b(gm|ch|[bsgpdm])\\s*\\d+\\b', x)\n",
        "    for code in ln_matches:\n",
        "        found_ranks.add(ln_map[code])\n",
        "\n",
        "    # MISSPELLINGS / VARIANTS\n",
        "    variations = {\n",
        "        'bronze': ['bronz', 'brnz', 'broze', 'bronce'],\n",
        "        'silver': ['silv', 'slvr', 'siver', 'sivler'],\n",
        "        'gold': ['gld', 'glod', 'goled', 'golden'],\n",
        "        'platinum': ['plat', 'pltn', 'platin', 'platen', 'platnium', 'platium'],\n",
        "        'diamond': ['diam', 'diamon', 'diamomd'],\n",
        "        'master': ['mstr', 'mst', 'masters'],\n",
        "        'grandmaster': ['grandm', 'gmaster'],\n",
        "        'challenger': ['chall', 'challngr', 'challen'],\n",
        "    }\n",
        "\n",
        "    for rank, vars_list in variations.items():\n",
        "        for var in vars_list:\n",
        "            if re.search(rf'\\b{var}\\b', x):\n",
        "                found_ranks.add(rank)\n",
        "                break\n",
        "\n",
        "    # HISTORICAL CONTEXT\n",
        "    if not found_ranks:\n",
        "        for rank in rank_order:\n",
        "            if re.search(rf'\\b(was|last\\s+season|previously)\\s+{rank}\\b', x):\n",
        "                found_ranks.add(rank)\n",
        "\n",
        "    # RETURN HIGHEST RANK\n",
        "    if found_ranks:\n",
        "        return max(found_ranks, key=lambda r: rank_order.index(r))\n",
        "\n",
        "    return np.nan"
      ],
      "metadata": {
        "id": "HEfyiV2RoIak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### extract_rank(x)\n",
        "\n",
        "function defined in order to clean up the very messy data of the 'League' variable column\n",
        "\n",
        "## Logic Flow (in order)\n",
        "**I. Input validation**\n",
        "* If x is empty or `NaN` → return `NaN`\n",
        "* Normalize text\n",
        "* Lowercase + strip spaces\n",
        "* Unranked detection (priority)\n",
        "\n",
        "**II. Uses *regex patterns* to catch:**\n",
        "1. **Unranked**\n",
        "  - “unranked”, “not ranked”, “no rank”\n",
        "  - placement/provisional\n",
        "  - casual-only players\n",
        "  - never played ranked\n",
        "  - rank anxiety / toxicity\n",
        "  - 0 ranked games\n",
        "\n",
        "  → Immediately returns 'unranked'\n",
        "\n",
        "**Special Case:** \"NA/Not Applicable\" or explicit declaration of League not being appilcable as stated in survey form is treated not as `NaN` or `NA` to differentiate from actual `NA` value being treated as 'Unknown' instead of 'Unranked'\n",
        "- not applicable → returns 'unranked'\n",
        "\n",
        "2. **Exact rank words**\n",
        "    \n",
        "    Matches whole words:\n",
        "- bronze, silver, gold, platinum, diamond, master, grandmaster, challenger\n",
        "3. **Letter-number ranks**\n",
        "Converts codes like:\n",
        "* B1 → bronze\n",
        "* P5 → platinum\n",
        "* GM1 → grandmaster\n",
        "* CH1 → challenger\n",
        "\n",
        "4. **Misspellings / variants**\n",
        "* Catches typos like:\n",
        "  * platnium → platinum\n",
        "  * glod → gold\n",
        "  * siver → silver\n",
        "  * bronce → bronze\n",
        "\n",
        "5. **Historical context**\n",
        "* Detects phrases like:\n",
        "  * \"was diamond\"\n",
        "  * \"last season gold\"\n",
        "\n",
        "**III. Resolution rule**\n",
        "* If multiple ranks found → return the highest rank using predefined order\n",
        "\n",
        "**IV. Fallback**\n",
        "* If nothing matched → return NaN"
      ],
      "metadata": {
        "id": "x_jY0lRl54k-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pre_df['League_clean'] = pre_df['League'].apply(extract_rank)"
      ],
      "metadata": {
        "id": "4HykXTGXXLch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Show and compare cleaned `League` categories\n",
        "\n",
        "# Filter rows where both 'League' and 'League_clean' are not NaN for display\n",
        "filtered_df = pre_df[pre_df['League'].notna() & pre_df['League_clean'].notna()].copy()\n",
        "\n",
        "# Get all unique clean league values to ensure all are covered\n",
        "unique_clean_leagues = filtered_df['League_clean'].unique()\n",
        "\n",
        "# Display examples for each unique clean league\n",
        "for league in sorted(unique_clean_leagues):\n",
        "    print(f\"\\nLeague_clean: {league.upper()}\")\n",
        "    display(filtered_df[filtered_df['League_clean'] == league][['League', 'League_clean']].head(3))\n",
        "    print(\"--------------------------------------------------------------------------------------\")\n"
      ],
      "metadata": {
        "id": "2UoVipsnpOyv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Clean `earnings` categories\n",
        "\n",
        "# Get the unique values to assess which values should stay or be removed\n",
        "# pre_df['earnings'].unique()\n",
        "# pre_df['earnings'].nunique()\n",
        "# pre_df['earnings'].drop_duplicates().to_csv(\"unique_earnings.csv\", index=False)"
      ],
      "metadata": {
        "id": "mZFJAiLebbsQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_earnings(x):\n",
        "    if pd.isna(x) or not str(x).strip():\n",
        "        return np.nan\n",
        "\n",
        "    x = str(x).lower().strip()\n",
        "\n",
        "    # 1. MONETIZATION / INCOME\n",
        "    monetization_keywords = [\n",
        "        'earn', 'earning', 'money', 'paid', 'income', 'living', 'wage',\n",
        "        'stream', 'streaming', 'youtube', 'tournament winnings',\n",
        "        'betting', 'trading', 'tuition', 'side income', 'make money',\n",
        "        'career', 'job', 'profitable', 'shoutcaster'\n",
        "    ]\n",
        "    if any(k in x for k in monetization_keywords):\n",
        "        return 'Monetization'\n",
        "\n",
        "    # 2. COMPETITIVE / PRO ASPIRATION\n",
        "    competitive_keywords = [\n",
        "        'competitive', 'competition', 'tournament', 'ranked',\n",
        "        'climb', 'ladder', 'improve', 'improvement', 'better',\n",
        "        'become', 'pro', 'professional', 'well known', 'best',\n",
        "        'aspire', 'goal', 'achieve', 'rank 1'\n",
        "    ]\n",
        "    if any(k in x for k in competitive_keywords):\n",
        "        return 'Competitive / Pro-Aspiration'\n",
        "\n",
        "    # 3. BOOSTING (explicit)\n",
        "    if 'boost' in x or 'eloboost' in x or 'boosting' in x:\n",
        "        return 'Boosting'\n",
        "\n",
        "    # 4. ESCAPISM\n",
        "    escapism_keywords = [\n",
        "        'escapism', 'escape', 'forget', 'real life', 'get away', 'relief',\n",
        "        'fill the void', 'numb', 'suppress', 'mental', 'memories'\n",
        "    ]\n",
        "    if any(k in x for k in escapism_keywords):\n",
        "        return 'Escapism'\n",
        "\n",
        "    # 5. ADDICTION (explicit psychological dependence)\n",
        "    addiction_keywords = [\n",
        "        'addicted', 'addiction', 'can’t stop', \"can't stop\",\n",
        "        'compulsion', 'dependent', 'hooked'\n",
        "    ]\n",
        "    if any(k in x for k in addiction_keywords):\n",
        "        return 'Addiction'\n",
        "\n",
        "    # 6. HABIT (automatic behavior, routine)\n",
        "    habit_keywords = [\n",
        "        'habit', 'routine', 'autopilot', 'used to', 'just play',\n",
        "        'normally play', 'always play', 'keep playing'\n",
        "    ]\n",
        "    if any(k in x for k in habit_keywords):\n",
        "        return 'Habit'\n",
        "\n",
        "    # 7. BOREDOM (time-filling behavior)\n",
        "    boredom_keywords = [\n",
        "        'bored', 'nothing better to do', 'kill time',\n",
        "        'pass time', 'spend my time', 'time somehow',\n",
        "        'waste time', 'no work', 'no job'\n",
        "    ]\n",
        "    if any(k in x for k in boredom_keywords):\n",
        "        return 'Boredom'\n",
        "\n",
        "    # 8. FUN & SOCIAL (default hobby class)\n",
        "    fun_keywords = [\n",
        "        'fun', 'friends', 'social', 'hobby',\n",
        "        'enjoy', 'love', 'passion', 'relax'\n",
        "    ]\n",
        "    if any(k in x for k in fun_keywords):\n",
        "        return 'Fun & Social'\n",
        "\n",
        "    # 9. FALLBACK\n",
        "    return 'Other / Just Playing'"
      ],
      "metadata": {
        "id": "ouj6OPF0sKoJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### extract_earnings(x)\n",
        "\n",
        "function defined in order to clean up and recategorize the data of the `earnings` variable column\n",
        "\n",
        "## Logic Flow (in order)\n",
        "**I. Input Validation**\n",
        "* If x is empty, blank, or NaN → return NaN\n",
        "* Normalize text:\n",
        "\t* Cast to string\n",
        "\t* Lowercase\n",
        "\t* Strip spaces\n",
        "\t* Normalize punctuation\n",
        "\n",
        "**II. Priority Semantic Classification *(ordered)***\n",
        "* Order matters — higher conceptual intent overrides lower ones\n",
        "1. **Monetization / Income Intent *(highest priority)***\n",
        "- Definition:\n",
        "Any explicit intention to earn money, profit, income, or financial gain through gaming.\n",
        "\n",
        "  Detected concepts:\n",
        "  - Direct earnings:\n",
        "    - “earn money”\n",
        "    - “earning”\n",
        "    - “income”\n",
        "    - “paid”\n",
        "    - “wage”\n",
        "    - “living”\n",
        "  - Career framing:\n",
        "    - “career”\n",
        "    - “job”\n",
        "    - “profession”\n",
        "    - “profitable”\n",
        "  - Content monetization:\n",
        "    - “streaming”\n",
        "    - “youtube”\n",
        "    - “content creation”\n",
        "    - “shoutcasting”\n",
        "  - Financial activities:\n",
        "    - “betting”\n",
        "    - “trading”\n",
        "    - “tournament winnings”\n",
        "    - “side income”\n",
        "  - Statements of intent:\n",
        "    - “make money”\n",
        "    - “support myself”\n",
        "    - “financially”\n",
        "\n",
        "  → Returns: `'Monetization'`\n",
        "2. **Competitive / Pro-Aspiration**\n",
        "- Definition:\n",
        "Non-monetary ambition to improve, compete, climb, or achieve status/recognition.\n",
        "\n",
        "  Detected concepts:\n",
        "  - Competition framing:\n",
        "    - “competitive”\n",
        "    - “competition”\n",
        "    - “tournaments”\n",
        "  - Performance goals:\n",
        "    - “improve”\n",
        "    - “get better”\n",
        "    - “climb”\n",
        "    - “ranked”\n",
        "    - “ladder”\n",
        "  - Identity/status:\n",
        "    - “become pro”\n",
        "    - “professional”\n",
        "    - “well known”\n",
        "    - “best”\n",
        "    - “rank 1”\n",
        "  - Aspirational language:\n",
        "    - “goal”\n",
        "    - “aspire”\n",
        "    - “achieve”\n",
        "  \n",
        "  → Returns: `'Competitive / Pro-Aspiration'`\n",
        "3. **Boosting**\n",
        "- Definition:\n",
        "Explicit commercial exploitation of skill ranking systems.\n",
        "\n",
        "  Detected concepts:\n",
        "\n",
        "  - “boosting”\n",
        "  - “elo boosting”\n",
        "  - “boost accounts”\n",
        "  - “selling rank”\n",
        "\n",
        "  → Returns: `'Boosting'`\n",
        "4. **Escapism**\n",
        "- Definition:\n",
        "Gaming used as emotional or psychological escape from reality.\n",
        "\n",
        "  Detected concepts:\n",
        "  - “escape”\n",
        "  - “forget real life”\n",
        "  - “get away”\n",
        "  - “relief”\n",
        "  - “numb”\n",
        "  - “suppress feelings”\n",
        "  - “mental health”\n",
        "  - “fill the void”\n",
        "  - “cope”\n",
        "  - “memories”\n",
        "\n",
        "  → Returns: `'Escapism'`\n",
        "5. **Addiction**\n",
        "- Definition:\n",
        "Explicit psychological dependence or compulsive behavior framing.\n",
        "\n",
        "  Detected concepts:\n",
        "    - “addicted”\n",
        "    - “addiction”\n",
        "    - “can't stop”\n",
        "    - “hooked”\n",
        "    - “dependent”\n",
        "    - “compulsion”\n",
        "    - “obsessed” (*pathological context*)\n",
        "\n",
        "  → Returns: `'Addiction'`\n",
        "6. **Habit**\n",
        "- Definition:\n",
        "Automatic, routine, non-emotional behavior.\n",
        "  Detected concepts:\n",
        "  “habit”\n",
        "  “routine”\n",
        "  “autopilot”\n",
        "  “just play”\n",
        "  “used to”\n",
        "  “always play”\n",
        "  “normally play”\n",
        "  “keep playing”\n",
        "\n",
        "  → Returns: 'Habit'\n",
        "7. **Boredom**\n",
        "- Definition:\n",
        "Time-filling behavior due to lack of alternatives.\n",
        "\n",
        "  Detected concepts:\n",
        "    - “bored”\n",
        "    - “nothing better to do”\n",
        "    - “kill time”\n",
        "    - “pass time”\n",
        "    - “waste time”\n",
        "    - “no work”\n",
        "    - “no job”\n",
        "    - “nothing else to do”\n",
        "\n",
        "  → Returns: `'Boredom'`\n",
        "8. **Fun & Social**\n",
        "- Definition:\n",
        "Healthy recreational motivation.\n",
        "\n",
        "  Detected concepts:\n",
        "    - “fun”\n",
        "    - “enjoy”\n",
        "    - “love”\n",
        "    - “hobby”\n",
        "    - “friends”\n",
        "    - “social”\n",
        "    - “relax”\n",
        "    - “passion”\n",
        "\n",
        "  → Returns: 'Fun & Social'\n",
        "\n",
        "**III. Resolution Rule**\n",
        "\n",
        "If multiple categories detected:\n",
        "→ Return the highest-priority category based on this order:\n",
        "\n",
        "> Monetization\n",
        "\n",
        "> Competitive / Pro-Aspiration\n",
        "\n",
        "> Boosting\n",
        "\n",
        "> Escapism\n",
        "\n",
        "> Addiction\n",
        "\n",
        "> Habit\n",
        "\n",
        "> Boredom\n",
        "\n",
        "> Fun & Social\n",
        "\n",
        "*Rationale*:\n",
        "Motivation hierarchy reflects behavioral dominance, not emotional tone.\n",
        "\n",
        "**IV. Fallback Rule**\n",
        "\n",
        "If nothing matches:\n",
        "→ Return `'Other / Just Playing'`"
      ],
      "metadata": {
        "id": "Ti8y18icsbhN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pre_df['earnings_clean'] = pre_df['earnings'].apply(extract_earnings)"
      ],
      "metadata": {
        "id": "zpghjtKtYJuf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Show and compare cleaned `earnings` categories and drop original column\n",
        "\n",
        "# Filter rows where both 'earnings' and 'earnings_clean' are not NaN for display\n",
        "filtered_df = pre_df[pre_df['earnings'].notna() & pre_df['earnings_clean'].notna()].copy()\n",
        "\n",
        "# Get all unique clean earnings values to ensure all are covered\n",
        "unique_clean_earnings = filtered_df['earnings_clean'].unique()\n",
        "\n",
        "# Display examples for each unique clean earnings\n",
        "for earnings in sorted(unique_clean_earnings):\n",
        "    print(f\"\\nearnings_clean: {earnings.upper()}\")\n",
        "    display(filtered_df[filtered_df['earnings_clean'] == earnings][['earnings', 'earnings_clean']].head(3))\n",
        "    print(\"--------------------------------------------------------------------------------------\")\n",
        "\n",
        "pre_df = pre_df.drop(columns=['earnings'])\n",
        "print(\"'earnings' column dropped\")"
      ],
      "metadata": {
        "id": "_7xhYBUSXXza"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Clean and analyze `SPIN{1-18}` variable columns\n",
        "\n",
        "spin_vars = [f'SPIN{i}' for i in range(1, 18)]\n",
        "\n",
        "# Show counts of nulls for just these columns\n",
        "null_counts = pre_df[spin_vars].isnull().sum()\n",
        "print(null_counts)"
      ],
      "metadata": {
        "id": "wPMU1LJloPQx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Analyze missing data patterns in `SPIN` variables\n",
        "\n",
        "# SPIN (Social Phobia Inventory) consists of 17 items measuring social anxiety.\n",
        "# This analysis checks: (1) missingness patterns, (2) completeness rates, and (3) whether people skip SPIN questions together.\n",
        "\n",
        "# Visualize missing data correlation for SPIN variables\n",
        "# (Do people who skip question A also skip question B?)\n",
        "plt.figure(figsize=(12, 8))\n",
        "msno.heatmap(pre_df[spin_vars])\n",
        "plt.title('Missing Data Pattern for SPIN Variables')\n",
        "plt.show()\n",
        "\n",
        "# Calculate SPIN completeness statistics\n",
        "spin_missing = pre_df[spin_vars].isnull().all(axis=1).sum()  # Skipped entire section\n",
        "spin_complete = (~pre_df[spin_vars].isnull().any(axis=1)).sum()  # Answered all questions\n",
        "spin_partial = len(pre_df) - spin_missing - spin_complete  # Answered some questions\n",
        "\n",
        "print(f\"People who skipped ALL SPIN questions: {spin_missing}\")\n",
        "print(f\"People who answered ALL SPIN questions: {spin_complete}\")\n",
        "print(f\"People with partial SPIN answers: {spin_partial}\")"
      ],
      "metadata": {
        "id": "J5mMm2tw0pnD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Remove respondents with incomplete `SPIN` data\n",
        "\n",
        "# Decision: Drop rows with missing SPIN values to ensure data quality for social phobia analysis.\n",
        "# Justification: 95%+ of respondents completed all SPIN items. The high correlation (0.7-0.9)\n",
        "# in missing data indicates systematic skipping (survey fatigue), making partial data unreliable.\n",
        "# Using complete cases only with N > 12,000 still provides sufficient statistical power.\n",
        "\n",
        "# Store original size for comparison\n",
        "original_size = len(pre_df)\n",
        "\n",
        "# Keep only people who answered ALL SPIN questions\n",
        "spin_vars = [f'SPIN{i}' for i in range(1, 18)]\n",
        "pre_df = pre_df.dropna(subset=spin_vars)\n",
        "\n",
        "# Report cleaning results\n",
        "rows_dropped = original_size - len(pre_df)\n",
        "pct_dropped = (rows_dropped / original_size) * 100\n",
        "\n",
        "print(f\"Original dataset: {original_size} people\")\n",
        "print(f\"After removing incomplete SPIN: {len(pre_df)} people\")\n",
        "print(f\"Rows dropped: {rows_dropped} ({pct_dropped:.1f}%)\")"
      ],
      "metadata": {
        "id": "pPKDBrMb1gjr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check missing values for other columns\n",
        "missing = pre_df.isnull().sum()\n",
        "missing_pct = (missing / len(pre_df)) * 100\n",
        "\n",
        "missing_summary = pd.DataFrame({\n",
        "    'Missing_Count': missing,\n",
        "    'Missing_Percentage': missing_pct\n",
        "})\n",
        "print(missing_summary[missing_summary['Missing_Count'] > 0].sort_values('Missing_Count', ascending=False))"
      ],
      "metadata": {
        "id": "EvcGprlvALCO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(pre_df['Degree'].unique())"
      ],
      "metadata": {
        "id": "dhcmA3P3AYaw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Handle missing values in `Degree` variable\n",
        "\n",
        "# Degree represents highest educational attainment with 11.6% missing (1,484 respondents).\n",
        "# Missing likely indicates: (1) no degree obtained, (2) currently pursuing education, or (3) privacy preference.\n",
        "\n",
        "# Decision: Create \"No degree / Not specified\" category rather than dropping rows.\n",
        "pre_df['Degree'] = pre_df['Degree'].fillna('No degree / Not specified')"
      ],
      "metadata": {
        "id": "M4QNBz2TAeuG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(pre_df['streams'].dtype)\n",
        "print(pre_df['streams'].describe())"
      ],
      "metadata": {
        "id": "myYGEFgWJ9Na"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Clean `Hours` and `streams` variables with logical constraints\n",
        "\n",
        "# Both Hours (playing) and streams (other activities) must satisfy: Hours + streams ≤ 168\n",
        "# Issues found: (1) streams > 168 (impossible alone), (2) Hours + streams > 168 (impossible combined)\n",
        "\n",
        "# Decision: Remove extreme outliers, then cap streams to ensure total ≤ 168\n",
        "\n",
        "# Step 1: Remove obvious data errors (streams > 168 individually)\n",
        "print(f\"Streams > 168 hours/week: {(pre_df['streams'] > 168).sum()}\")\n",
        "pre_df.loc[pre_df['streams'] > 168, 'streams'] = np.nan\n",
        "\n",
        "# Step 2: Check for impossible combinations\n",
        "pre_df['total_gaming_time'] = pre_df['Hours'] + pre_df['streams'].fillna(0)\n",
        "impossible = (pre_df['total_gaming_time'] > 168).sum()\n",
        "print(f\"Cases where Hours + streams > 168: {impossible}\")\n",
        "\n",
        "# Step 3: Cap streams to ensure Hours + streams ≤ 168\n",
        "# Only adjust if Hours is valid\n",
        "mask = (pre_df['Hours'].notna()) & (pre_df['streams'].notna())\n",
        "pre_df.loc[mask & (pre_df['total_gaming_time'] > 168), 'streams'] = \\\n",
        "    np.maximum(0, 168 - pre_df.loc[mask & (pre_df['total_gaming_time'] > 168), 'Hours'])\n",
        "\n",
        "# Step 4: Fill remaining missing streams with 0\n",
        "pre_df['streams'] = pre_df['streams'].fillna(0)\n",
        "\n",
        "# Step 5: Verify and clean up\n",
        "pre_df['total_gaming_time'] = pre_df['Hours'] + pre_df['streams']\n",
        "print(f\"\\nAfter cleaning:\")\n",
        "print(f\"Max Hours + streams: {pre_df['total_gaming_time'].max()}\")\n",
        "print(f\"Cases > 168: {(pre_df['total_gaming_time'] > 168).sum()}\")\n",
        "\n",
        "# Drop temporary column\n",
        "pre_df = pre_df.drop(columns=['total_gaming_time'])\n",
        "\n",
        "print(f\"\\nstreams summary:\")\n",
        "print(pre_df['streams'].describe())"
      ],
      "metadata": {
        "id": "E7MVsLeuMWF3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Remove rows with missing `Hours` (gaming hours per week)\n",
        "\n",
        "# Hours represents weekly gaming time - a critical predictor variable.\n",
        "# Only 28 respondents (0.2%) missing this value.\n",
        "\n",
        "# Decision: Drop these rows.\n",
        "# Justification: Hours is central to research on gaming behavior and mental health.\n",
        "# Cannot reliably estimate gaming time. Minimal data loss (0.2%) makes row deletion acceptable.\n",
        "\n",
        "pre_df = pre_df.dropna(subset=['Hours'])"
      ],
      "metadata": {
        "id": "1LXpZYvkNddS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Remove rows with missing `Narcissism` scores\n",
        "\n",
        "# Narcissism is a psychological scale measuring narcissistic personality traits.\n",
        "# Only 11 respondents (0.1%) missing this value.\n",
        "\n",
        "# Decision: Drop these rows\n",
        "# Justification: Psychological scales should not be imputed (unethical to guess personality traits).\n",
        "# Negligible data loss (0.1%) makes row deletion the appropriate choice.\n",
        "\n",
        "pre_df = pre_df.dropna(subset=['Narcissism'])"
      ],
      "metadata": {
        "id": "3K650wVwN3Qd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Clean `Hours` values\n",
        "\n",
        "# Remove rows where Hours > 168 (impossible in a week).\n",
        "pre_df = pre_df[pre_df['Hours'] <= 168]\n",
        "\n",
        "print(f\"Max Hours after filter: {pre_df['Hours'].max()}\")"
      ],
      "metadata": {
        "id": "lo6Niw9bfk0-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Cleaning `Platform` and `WhyPlay`\n",
        "\n",
        "# Inconsistent text needs to be simplified for better grouping of data\n",
        "\n",
        "# 1. Clean Platform\n",
        "def clean_platform(platform):\n",
        "    if pd.isna(platform):\n",
        "        return \"Unknown\"\n",
        "\n",
        "    # Force to string to handle any non-text data\n",
        "    platform = str(platform)\n",
        "\n",
        "    if \"Console\" in platform:\n",
        "        return \"Console\"\n",
        "    if \"Smartphone\" in platform:\n",
        "        return \"Mobile\"\n",
        "    return platform\n",
        "\n",
        "# 2. Clean whyplay\n",
        "def clean_whyplay(text):\n",
        "    if pd.isna(text):\n",
        "        return \"Other\"\n",
        "\n",
        "    text = str(text).lower()\n",
        "\n",
        "    # Priority grouping based on keywords\n",
        "    if \"improve\" in text or \"improving\" in text:\n",
        "        return \"Improving\"\n",
        "    if \"win\" in text or \"winning\" in text:\n",
        "        return \"Winning\"\n",
        "    if \"relax\" in text:\n",
        "        return \"Relaxing\"\n",
        "    if \"fun\" in text:\n",
        "        return \"Fun\"\n",
        "\n",
        "    return \"Other\"\n",
        "\n",
        "# Apply the cleaning functions\n",
        "pre_df['Platform_Clean'] = pre_df['Platform'].apply(clean_platform)\n",
        "pre_df['WhyPlay_Clean'] = pre_df['whyplay'].apply(clean_whyplay)\n",
        "\n",
        "# Visualize the standardized groups\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "sns.countplot(x='Platform_Clean', data=pre_df, ax=axes[0])\n",
        "axes[0].set_title('Distribution of Gaming Platforms')\n",
        "\n",
        "sns.countplot(y='WhyPlay_Clean', data=pre_df, order=pre_df['WhyPlay_Clean'].value_counts().index, ax=axes[1])\n",
        "axes[1].set_title('Distribution of Primary Motivations')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CXaBA9lHfvMm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check missing values for other columns\n",
        "missing = pre_df.isnull().sum()\n",
        "missing_pct = (missing / len(pre_df)) * 100\n",
        "\n",
        "missing_summary = pd.DataFrame({\n",
        "    'Missing_Count': missing,\n",
        "    'Missing_Percentage': missing_pct\n",
        "})\n",
        "print(missing_summary[missing_summary['Missing_Count'] > 0].sort_values('Missing_Count', ascending=False))"
      ],
      "metadata": {
        "id": "kw8cumPSn8-1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pre_df['League_clean'].unique()"
      ],
      "metadata": {
        "id": "aD4hSFpioVpJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Consolidate League_clean missing values to 'unranked' category\n",
        "\n",
        "# League_clean already contains 'unranked' values from extract_rank() function (for explicit text like \"don't play ranked\").\n",
        "# However, some missing values (NaN) still exist from completely blank entries in original League field.\n",
        "\n",
        "# Decision: Convert remaining NaN to 'unranked' to consolidate all non-ranked players into one category.\n",
        "# Justification: Both explicit \"unranked\" responses and blank entries represent players who don't play ranked mode.\n",
        "\n",
        "# full distribution before converting NaN to 'unranked'\n",
        "print(\"\\nLeague_clean distribution:\")\n",
        "print(pre_df['League_clean'].value_counts().sort_index())\n",
        "\n",
        "print(\"Converting 2191 NaN League_clean rows to 'unranked'...\")\n",
        "# Convert NaN to 'unranked'\n",
        "pre_df['League_clean'] = pre_df['League_clean'].fillna('unranked')\n",
        "\n",
        "# Show full distribution after conversion\n",
        "print(\"\\nLeague_clean distribution:\")\n",
        "print(pre_df['League_clean'].value_counts().sort_index())\n",
        "\n",
        "pre_df = pre_df.drop(columns=['League'])\n",
        "print(\"'League' column dropped\")\n",
        "print(f\"\\nFinal League_clean categories: {pre_df['League_clean'].nunique()}\")\n",
        "print(pre_df['League_clean'].value_counts())"
      ],
      "metadata": {
        "id": "SjxDwYMlqYsR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Remove rows with missing Birthplace_ISO3\n",
        "\n",
        "# Birthplace_ISO3 represents country of birth (3-letter ISO country code).\n",
        "# Only 109 respondents (0.9%) missing this value.\n",
        "\n",
        "# Decision: Drop these rows if geographic origin is relevant to analysis.\n",
        "# Justification: Geographic/cultural background may influence gaming behavior and social connectedness.\n",
        "# Minimal data loss (0.9%) makes row deletion acceptable if birthplace is needed for demographic analysis.\n",
        "\n",
        "pre_df = pre_df.dropna(subset=['Birthplace_ISO3'])"
      ],
      "metadata": {
        "id": "0OT0dXyirQw8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Remove rows with missing Residence_ISO3\n",
        "\n",
        "# Residence_ISO3 represents current country of residence (3-letter ISO country code).\n",
        "# Only 101 respondents (0.8%) missing this value.\n",
        "\n",
        "# Decision: Drop these rows if current location is relevant to analysis.\n",
        "# Justification: Current residence may affect gaming culture, community access, and social factors.\n",
        "# Minimal data loss (0.8%) makes row deletion acceptable if residence is needed for geographic analysis.\n",
        "\n",
        "pre_df = pre_df.dropna(subset=['Residence_ISO3'])"
      ],
      "metadata": {
        "id": "UHKnxssGr_CG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Remove rows with missing Work (employment status)\n",
        "\n",
        "# Work represents employment status (e.g., Employed, Student, Unemployed).\n",
        "# Only 31 respondents (0.2%) missing this value.\n",
        "\n",
        "# Decision: Drop these rows.\n",
        "# Justification: Employment status is important demographic context for understanding gaming patterns\n",
        "# and time availability. Minimal data loss (0.2%) makes row deletion preferable to imputation.\n",
        "\n",
        "pre_df = pre_df.dropna(subset=['Work'])"
      ],
      "metadata": {
        "id": "m7ldgz0FsNrl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check missing values for other columns\n",
        "missing = pre_df.isnull().sum()\n",
        "missing_pct = (missing / len(pre_df)) * 100\n",
        "\n",
        "missing_summary = pd.DataFrame({\n",
        "    'Missing_Count': missing,\n",
        "    'Missing_Percentage': missing_pct\n",
        "})\n",
        "print(missing_summary[missing_summary['Missing_Count'] > 0].sort_values('Missing_Count', ascending=False))"
      ],
      "metadata": {
        "id": "lELvJeDPq0F2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Clean GADE missing values using categorical imputation\n",
        "\n",
        "# GADE contains NA (not applicable) values.\n",
        "# 615 respondents (4.89%) missing this value.\n",
        "\n",
        "# Decision: Use categorical imputation to replace the missing values\n",
        "# Justification: Using the most common response as the baseline for missing data will preserve the overall distribution.\n",
        "\n",
        "# Check missing count\n",
        "print(f\"Missing GADE values (before): {pre_df['GADE'].isnull().sum()}\")\n",
        "\n",
        "# Calculate the mode (most common value)\n",
        "gade_mode = pre_df['GADE'].mode()[0]\n",
        "print(f\"Most common value (Mode): {gade_mode}\")\n",
        "\n",
        "# Fill missing values with the mode\n",
        "pre_df['GADE'] = pre_df['GADE'].fillna(gade_mode)\n",
        "\n",
        "# Verify cleanup\n",
        "print(f\"Missing GADE values (after): {pre_df['GADE'].isnull().sum()}\")\n",
        "print(pre_df['GADE'].value_counts())"
      ],
      "metadata": {
        "id": "ba6CmZARBNYo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pre_df.info()"
      ],
      "metadata": {
        "id": "zW2L8lQjs-YB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exploratory Data Analysis"
      ],
      "metadata": {
        "id": "_MKnh36kgoqf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gaming_df = pre_df\n",
        "gaming_df_multiplayer = gaming_df[gaming_df[\"Playstyle\"].str.contains(\"Multiplayer\", case=False, na=False)]\n",
        "gamingdf_use = gaming_df_multiplayer[[\"Hours\", \"SWL_T\", \"SPIN_T\"]].copy()"
      ],
      "metadata": {
        "id": "SAZFgqUygtru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gamingdf_use.info()"
      ],
      "metadata": {
        "id": "VeG5HxVZooXA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Variables\n",
        "\n",
        "1. Hours\n",
        "2. SWL_T\n",
        "3. SPIN_T"
      ],
      "metadata": {
        "id": "XCtUqPS3qrYo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gamingdf_use[\"Hours\"].describe()"
      ],
      "metadata": {
        "id": "AY3WyR7Yorvd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gamingdf_use[\"SPIN_T\"].describe()"
      ],
      "metadata": {
        "id": "SiUI4Gj6pmkJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gamingdf_use[\"SWL_T\"].describe()"
      ],
      "metadata": {
        "id": "k_XqGSGrpopC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(gamingdf_use[\"Hours\"], bins=30)\n",
        "plt.title(\"Distribution of Multiplayer Gaming Hours\")\n",
        "plt.xlabel(\"Hours\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FvZ9OFk9ptbt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q1. Is multiplayer playtime associated with social anxiety (SPIN_T)?"
      ],
      "metadata": {
        "id": "yAqi9BBMqjAW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(gamingdf_use[\"Hours\"], gamingdf_use[\"SPIN_T\"])\n",
        "plt.xlabel(\"Multiplayer Hours\")\n",
        "plt.ylabel(\"Social Anxiety (SPIN_T)\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "j1GbO_GgqzLF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gamingdf_use[[\"Hours\", \"SPIN_T\"]].corr(method=\"spearman\")"
      ],
      "metadata": {
        "id": "bQYcw8CQq3lN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "gamingdf_use[[\"Hours\", \"SPIN_T\"]].corr(method=\"pearson\")"
      ],
      "metadata": {
        "id": "XDi19LGSq4dN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q2. Is gaming time associated with life satisfaction (SWL_T)?"
      ],
      "metadata": {
        "id": "DpLTwVYMq8qn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(gamingdf_use[\"Hours\"], gamingdf_use[\"SWL_T\"])\n",
        "plt.xlabel(\"Multiplayer Hours\")\n",
        "plt.ylabel(\"Life Satisfaction (SWL_T)\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RcncvaeUq_h-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gamingdf_use[[\"Hours\", \"SWL_T\"]].corr(method=\"spearman\")"
      ],
      "metadata": {
        "id": "NQ8jj6vSrc7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gamingdf_use[[\"Hours\", \"SWL_T\"]].corr(method=\"pearson\")"
      ],
      "metadata": {
        "id": "ZRXEw2n1reBg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}